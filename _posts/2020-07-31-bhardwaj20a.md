---
title: Information Theoretic Model Predictive Q-Learning
abstract: Model-free Reinforcement Learning (RL) works well when experience can be
  collected cheaply and model-based RL is effective when system dynamics can be modeled
  accurately. However, both assumptions can be violated in real world problems such
  as robotics, where querying the system can be expensive and real-world dynamics
  can be difficult to model. In contrast to RL, Model Predictive Control (MPC) algorithms
  use a simulator to optimize a simple policy class online, constructing a closed-loop
  controller that can effectively contend with real-world dynamics. MPC performance
  is usually limited by factors such as model bias and the limited horizon of optimization.
  In this work, we present a novel theoretical connection between information theoretic
  MPC and entropy regularized RL and develop a Q-learning algorithm that can leverage
  biased models. We validate the proposed algorithm on sim-to-sim control tasks to
  demonstrate the improvements over optimal control and reinforcement learning from
  scratch. Our approach paves the way for deploying reinforcement learning algorithms
  on real systems in a systematic manner.
layout: inproceedings
series: Proceedings of Machine Learning Research
issn: 2640-3498
id: bhardwaj20a
month: 0
tex_title: Information Theoretic Model Predictive Q-Learning
firstpage: 840
lastpage: 850
page: 840-850
order: 840
cycles: false
bibtex_author: Bhardwaj, Mohak and Handa, Ankur and Fox, Dieter and Boots, Byron
author:
- given: Mohak
  family: Bhardwaj
- given: Ankur
  family: Handa
- given: Dieter
  family: Fox
- given: Byron
  family: Boots
date: 2020-07-31
address: 
publisher: PMLR
container-title: Proceedings of the 2nd Conference on Learning for Dynamics and Control
volume: '120'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 7
  - 31
pdf: http://proceedings.mlr.press/v120/bhardwaj20a/bhardwaj20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
