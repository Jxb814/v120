---
title: Hamilton-Jacobi-Bellman Equations for Q-Learning in Continuous Time
abstract: In this paper, we introduce Hamilton-Jacobi-Bellman (HJB) equations for
  Q-functions in continuous time optimal control problems with Lipschitz continuous
  controls. The standard Q-function used in reinforcement learning is shown to be
  the unique viscosity solution of the HJB equation. A necessary and sufficient condition
  for optimality is provided using the viscosity solution framework. By using the
  HJB equation, we develop a Q-learning method for continuous-time dynamical systems.
  A DQN-like algorithm is also proposed for high-dimensional state and control spaces.
  The performance of the proposed Q-learning algorithm is demonstrated using 1-, 10-
  and 20-dimensional dynamical systems.
layout: inproceedings
series: Proceedings of Machine Learning Research
issn: 2640-3498
id: kim20b
month: 0
tex_title: Hamilton-Jacobi-Bellman Equations for Q-Learning in Continuous Time
firstpage: 739
lastpage: 748
page: 739-748
order: 739
cycles: false
bibtex_author: Kim, Jeongho and Yang, Insoon
author:
- given: Jeongho
  family: Kim
- given: Insoon
  family: Yang
date: 2020-07-31
address: 
publisher: PMLR
container-title: Proceedings of the 2nd Conference on Learning for Dynamics and Control
volume: '120'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 7
  - 31
pdf: http://proceedings.mlr.press/v120/kim20b/kim20b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
