---
title: Tractable Reinforcement Learning of Signal Temporal Logic Objectives
abstract: Signal temporal logic (STL) is an expressive language to specify time-bound
  real-world robotic tasks and safety specifications. Recently, there has been an
  interest in learning optimal policies to satisfy STL specifications via reinforcement
  learning (RL). Learning to satisfy STL specifications often needs a sufficient length
  of state history to compute reward and the next action. The need for history results
  in exponential state-space growth for the learning problem. Thus the learning problem
  becomes computationally intractable for most real-world applications. In this paper,
  we propose a compact means to capture state history in a new augmented state-space
  representation. An approximation to the objective (maximizing probability of satisfaction)
  is proposed and solved for in the new augmented state-space. We show the performance
  bound of the approximate solution and compare it with the solution of an existing
  technique via simulations.
layout: inproceedings
series: Proceedings of Machine Learning Research
issn: 2640-3498
id: venkataraman20a
month: 0
tex_title: Tractable Reinforcement Learning of Signal Temporal Logic Objectives
firstpage: 308
lastpage: 317
page: 308-317
order: 308
cycles: false
bibtex_author: Venkataraman, Harish and Aksaray, Derya and Seiler, Peter
author:
- given: Harish
  family: Venkataraman
- given: Derya
  family: Aksaray
- given: Peter
  family: Seiler
date: 2020-07-31
address: 
publisher: PMLR
container-title: Proceedings of the 2nd Conference on Learning for Dynamics and Control
volume: '120'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 7
  - 31
pdf: http://proceedings.mlr.press/v120/venkataraman20a/venkataraman20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
